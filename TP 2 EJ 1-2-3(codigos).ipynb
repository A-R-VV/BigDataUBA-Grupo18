{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8613b1-54eb-45b5-8242-bb28f6100c8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\facun\\\\OneDrive\\\\Documentos\\\\usu_individual_T104.dta'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Desde la ubicacion de los archivos copiamos los codigo de ruta y cargamos las bases de datos\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df_2004 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfacun\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocumentos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124musu_individual_T104.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m df_2024 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfacun\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocumentos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124musu_individual_T124.xlsx.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Estandarizar nombres de columnas a mayúsculas\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:2109\u001b[0m, in \u001b[0;36mread_stata\u001b[1;34m(filepath_or_buffer, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals, chunksize, iterator, compression, storage_options)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader:\n\u001b[1;32m-> 2109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1683\u001b[0m, in \u001b[0;36mStataReader.read\u001b[1;34m(self, nrows, convert_dates, convert_categoricals, index_col, convert_missing, preserve_dtypes, columns, order_categoricals)\u001b[0m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_read_method_doc)\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[0;32m   1673\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1681\u001b[0m     order_categoricals: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1682\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 1683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_open()\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# Handle options\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1175\u001b[0m, in \u001b[0;36mStataReader._ensure_open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03mEnsure the file has been opened and its header data read.\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_path_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_file()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\stata.py:1188\u001b[0m, in \u001b[0;36mStataReader._open_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_entered:\n\u001b[0;32m   1182\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStataReader is being used without using a context manager. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing StataReader as a context manager is the only supported method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;167;01mResourceWarning\u001b[39;00m,\n\u001b[0;32m   1186\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1187\u001b[0m     )\n\u001b[1;32m-> 1188\u001b[0m handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_path_or_buf,\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1191\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_options,\n\u001b[0;32m   1192\u001b[0m     is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1193\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression,\n\u001b[0;32m   1194\u001b[0m )\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;66;03m# If the handle is directly seekable, use it without an extra copy.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_or_buf \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\facun\\\\OneDrive\\\\Documentos\\\\usu_individual_T104.dta'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Desde la ubicacion de los archivos copiamos los codigo de ruta y cargamos las bases de datos\n",
    "df_2004 = pd.read_stata(r\"C:\\Users\\facun\\OneDrive\\Documentos\\usu_individual_T104.dta\")\n",
    "df_2024 = pd.read_excel(r\"C:\\Users\\facun\\OneDrive\\Documentos\\usu_individual_T124.xlsx.xlsx\")\n",
    "\n",
    "# Estandarizar nombres de columnas a mayúsculas\n",
    "df_2004.columns = df_2004.columns.str.upper()\n",
    "df_2024.columns = df_2024.columns.str.upper()\n",
    "\n",
    "# Ya que la Patagonia es la region elegida buscamos su correcta denominacion y filtramos\n",
    "df_2004['REGION'] = df_2004['REGION'].astype(str)\n",
    "df_2024['REGION'] = df_2024['REGION'].astype(str)\n",
    "\n",
    "df_2004 = df_2004[df_2004['REGION'] == 'Patagónica']\n",
    "df_2024 = df_2024[df_2024['REGION'] == '43']  \n",
    "\n",
    "# Agregamos ambas columnas con su correspondiente año\n",
    "df_2004['ANO4'] = 2004\n",
    "df_2024['ANO4'] = 2024\n",
    "\n",
    "# Seleccionar variables comunes elegidas\n",
    "variables_seleccionadas = [\n",
    "    'P47T', 'IPCF', 'CH04', 'CH06', 'CH08', \n",
    "    'P21', 'CAT_INAC', 'PP04D_COD', 'PP04A', 'TRIMESTRE',\n",
    "    'REGION', 'AGLOMERADO', 'IDECCFR', 'ANO4', 'ESTADO'\n",
    "]\n",
    "\n",
    "# Convertir variables numéricas\n",
    "numeric_vars = ['CH06', 'IPCF', 'P21', 'P47T']\n",
    "for var in numeric_vars:\n",
    "    if var in df_2004.columns:\n",
    "        df_2004[var] = pd.to_numeric(df_2004[var], errors='coerce')\n",
    "    if var in df_2024.columns:\n",
    "        df_2024[var] = pd.to_numeric(df_2024[var], errors='coerce')\n",
    "\n",
    "# Unimos lo data frames de ambos años trabajados\n",
    "df_combinado = pd.concat(\n",
    "    [df_2004[variables_seleccionadas], df_2024[variables_seleccionadas]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Verificar observaciones por año\n",
    "print(\"Conteo de observaciones por año:\")\n",
    "print(df_combinado['ANO4'].value_counts())\n",
    "\n",
    "# Análisis de valores faltantes\n",
    "valores_faltantes = df_combinado[variables_seleccionadas].isna().sum()\n",
    "print(\"Valores faltantes por variable:\")\n",
    "print(valores_faltantes)\n",
    "\n",
    "# Agrupar por \"ANO4\" y calcular los valores faltantes sin incluir la columna de agrupación\n",
    "faltantes_por_anio = df_combinado.groupby(\"ANO4\", group_keys=False).apply(lambda df: df.isnull().sum())\n",
    "faltantes_por_anio = faltantes_por_anio.transpose()\n",
    "\n",
    "# Visualizamos resultados\n",
    "print(\"Valores faltantes por año:\")\n",
    "print(faltantes_por_anio)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8657976-747b-440c-97f6-f8d8063ad739",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combinado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Reemplazar los valores de CH04 por etiquetas\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_combinado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH04\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_combinado[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH04\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace({\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVarón\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMujer\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Agrupar por año y sexo y contar\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sexo_agrupado \u001b[38;5;241m=\u001b[39m df_combinado\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANO4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH04\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39munstack()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_combinado' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reemplazar los valores de CH04 por etiquetas\n",
    "df_combinado['CH04'] = df_combinado['CH04'].replace({1: 'Varón', 2: 'Mujer'})\n",
    "\n",
    "# Agrupar por año y sexo y contar\n",
    "sexo_agrupado = df_combinado.groupby(['ANO4', 'CH04']).size().unstack()\n",
    "\n",
    "# Calcular porcentajes por año\n",
    "sexo_porcentaje = sexo_agrupado.div(sexo_agrupado.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Crear gráfico\n",
    "ax = sexo_porcentaje.plot(kind='bar', figsize=(8, 6), color=['pink', 'blue'], edgecolor='black')\n",
    "\n",
    "# Estética del gráfico\n",
    "plt.title('Composición por sexo en la región Patagónica (2004 vs 2024)', fontsize=14)\n",
    "plt.ylabel('Porcentaje (%)')\n",
    "plt.xlabel('Año')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.yticks(range(0, 101, 10))  # Porcentajes de 10 en 10\n",
    "plt.legend(title='Sexo')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Agregar etiquetas de porcentaje en cada barra\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.1f%%', label_type='edge', fontsize=10)\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab535a86-bed8-4441-9b8a-97967d308eda",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_2004' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m variables_seleccionadas \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP47T\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIPCF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH04\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH06\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH07\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCH08\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNIVEL_ED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP21\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCAT_INAC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP04D_COD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPP04A\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRIMESTRE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREGION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGLOMERADO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDECCFR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANO4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESTADO\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Unir los datasets con las nuevas variables seleccionadas\u001b[39;00m\n\u001b[0;32m      9\u001b[0m df_combinado \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(\n\u001b[1;32m---> 10\u001b[0m     [df_2004[variables_seleccionadas], df_2024[variables_seleccionadas]],\n\u001b[0;32m     11\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_2004' is not defined"
     ]
    }
   ],
   "source": [
    "# Seleccionar variables comunes elegidas (ahora incluyendo CH07 y NIVEL_ED)\n",
    "variables_seleccionadas = [\n",
    "    'P47T', 'IPCF', 'CH04', 'CH06', 'CH07', 'CH08',\n",
    "    'NIVEL_ED', 'P21', 'CAT_INAC', 'PP04D_COD', 'PP04A', 'TRIMESTRE',\n",
    "    'REGION', 'AGLOMERADO', 'IDECCFR', 'ANO4', 'ESTADO'\n",
    "]\n",
    "\n",
    "# Unir los datasets con las nuevas variables seleccionadas\n",
    "df_combinado = pd.concat(\n",
    "    [df_2004[variables_seleccionadas], df_2024[variables_seleccionadas]],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d55132df-7b2a-4b40-9f54-db42ed9ab1a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combinado' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Asegurarse de que todas las variables sean numéricas\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m variables_correlacion:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m df_combinado\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     23\u001b[0m         df_combinado[var] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df_combinado[var], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Filtrar por año\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_combinado' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Diccionario con nombres descriptivos de las variables\n",
    "nombres_variables = {\n",
    "    'CH04': 'Sexo',\n",
    "    'CH06': 'Edad',\n",
    "    'CH07': 'Estado Civil',\n",
    "    'CH08': 'Parentesco',\n",
    "    'NIVEL_ED': 'Nivel Educativo',\n",
    "    'ESTADO': 'Condición de Actividad',\n",
    "    'CAT_INAC': 'Categoría de Inactividad',\n",
    "    'IPCF': 'Ingreso per Cápita Familiar'\n",
    "}\n",
    "\n",
    "# Variables a correlacionar\n",
    "variables_correlacion = list(nombres_variables.keys())\n",
    "\n",
    "# Asegurarse de que todas las variables sean numéricas\n",
    "for var in variables_correlacion:\n",
    "    if var in df_combinado.columns:\n",
    "        df_combinado[var] = pd.to_numeric(df_combinado[var], errors='coerce')\n",
    "\n",
    "# Filtrar por año\n",
    "df_2004_corr = df_combinado[df_combinado['ANO4'] == 2004][variables_correlacion].rename(columns=nombres_variables)\n",
    "df_2024_corr = df_combinado[df_combinado['ANO4'] == 2024][variables_correlacion].rename(columns=nombres_variables)\n",
    "\n",
    "# Graficar heatmaps\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Año 2004\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(df_2004_corr.corr(), annot=True, cmap='viridis', fmt=\".2f\", square=True)\n",
    "plt.title('Matriz de Correlación - Año 2004')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Año 2024\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(df_2024_corr.corr(), annot=True, cmap='viridis', fmt=\".2f\", square=True)\n",
    "plt.title('Matriz de Correlación - Año 2024')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e28e8-6a0e-411f-ba5b-e2c9bebb51a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7fdb144-c200-4c2f-b630-dab138937722",
   "metadata": {},
   "source": [
    "PARTE III\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf415732-5759-40c3-a771-343d25ec9817",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'EPH_2004.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar los datos de los archivos CSV\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data_2004 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPH_2004.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m data_2024 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPH_2024.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Ver las primeras filas para asegurarnos de que los datos se importaron correctamente\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EPH_2004.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de los archivos CSV\n",
    "data_2004 = pd.read_csv('EPH_2004.csv')\n",
    "data_2024 = pd.read_csv('EPH_2024.csv')\n",
    "\n",
    "# Ver las primeras filas para asegurarnos de que los datos se importaron correctamente\n",
    "print(data_2004.head())\n",
    "print(data_2024.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b95256-c342-4783-91c9-b267fea39b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas duplicadas\n",
    "data_2004 = data_2004.drop_duplicates()\n",
    "data_2024 = data_2024.drop_duplicates()\n",
    "\n",
    "# Eliminar valores nulos en columnas específicas\n",
    "data_2004 = data_2004.dropna(subset=['columna_interes'])\n",
    "data_2024 = data_2024.dropna(subset=['columna_interes'])\n",
    "\n",
    "# Verificar que no hay más valores nulos\n",
    "print(data_2004.isnull().sum())\n",
    "print(data_2024.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a86619-54bf-4c0b-b02a-36ff0ae044a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualización de distribución de una columna\n",
    "sns.histplot(data_2004['columna_interes'], kde=True)\n",
    "plt.title('Distribución de columna_interes 2004')\n",
    "plt.show()\n",
    "\n",
    "# Visualización de una correlación entre dos variables\n",
    "sns.heatmap(data_2004.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de correlación 2004')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33397c6e-e5a8-492e-828c-2d29c929b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Estandarizar las variables numéricas\n",
    "scaler = StandardScaler()\n",
    "data_2004[['columna_numérica1', 'columna_numérica2']] = scaler.fit_transform(data_2004[['columna_numérica1', 'columna_numérica2']])\n",
    "\n",
    "# Codificar variables categóricas\n",
    "encoder = LabelEncoder()\n",
    "data_2004['columna_categorica'] = encoder.fit_transform(data_2004['columna_categorica'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50d0d4-f083-48ed-b043-8499f7885c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%) y prueba (20%)\n",
    "X = data_2004.drop('columna_objetivo', axis=1)  # Variables independientes\n",
    "y = data_2004['columna_objetivo']  # Variable dependiente (objetivo)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c117f77e-44b9-42d4-bfd5-ed9cfae10e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Selección de modelos\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_rf = RandomForestRegressor()\n",
    "\n",
    "# Ajustar los modelos a los datos de entrenamiento\n",
    "modelo_lr.fit(X_train, y_train)\n",
    "modelo_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965db22f-0313-4610-9aa4-47a5f3cf5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los modelos ya fueron entrenados en el paso anterior\n",
    "# Aquí podemos predecir utilizando los datos de prueba\n",
    "\n",
    "predicciones_lr = modelo_lr.predict(X_test)\n",
    "predicciones_rf = modelo_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376e9de-b48b-421a-a4f8-f5b398a1754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Evaluar los modelos\n",
    "mse_lr = mean_squared_error(y_test, predicciones_lr)\n",
    "mse_rf = mean_squared_error(y_test, predicciones_rf)\n",
    "\n",
    "r2_lr = r2_score(y_test, predicciones_lr)\n",
    "r2_rf = r2_score(y_test, predicciones_rf)\n",
    "\n",
    "print(f'MSE Regresión Lineal: {mse_lr}')\n",
    "print(f'MSE Random Forest: {mse_rf}')\n",
    "print(f'R2 Regresión Lineal: {r2_lr}')\n",
    "print(f'R2 Random Forest: {r2_rf}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
